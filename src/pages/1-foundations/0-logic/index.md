---
title: Logic
description: ""
layout: "../../../components/layouts/ChapterLayout.astro"
---

There are (roughly) two ways of reasoning: the proof and the experiment. 

Proofs are the domain of mathematics and are rooted in logic, which studies how conclusions follow from *premises*. Logic and proof deal with certainties. Given a set of true premises, manipulations and combinations of these premises will lead to conclusions that are either true or false. Well, *usually*. In practice, there's a third kind of statement: the undecidable (more on that in section 1.X). 

Meanwhile, experiments are the domain of science and are rooted in probability theory, which studies how conclusions follow from *evidence*. Probability theory and experiment deal in uncertainties; they relax logic's duality of true and false for a spectrum of degrees of belief[^1]. 

[^1]: Throughout this book, we'll be sticking to a Bayesian framing. See chapter 4. In this light, every interaction with reality can be seen as an experiment.

Logic and probability theory codify what it means to reason. As such, they've been the basis of artificial reasoning since day one. Though modern machine learning has drifted more towards the latter and away from the former, at the very least logic offers a powerful set of tools to help us understand AIs — in particular phenomena like self-reference. In the limiting case, one could hope for provably beneficial AIs, to which we will return in later chapters. 

Understanding the unification of the two modes of reasoning is an active area of research, with the aim of establishing an understanding of *reflectve stability*, intelligent machines that can self-modify and need to make decisions about how to do so.[@dremski20XX] 

In chapter X, we'll see how logical induction provides such a unification. But first, the basics of logic

# Propositional Logic



# First-Order Logic



# Computability



# Incompleteness